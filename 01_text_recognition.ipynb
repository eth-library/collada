{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR\n",
    "To do any sort of content analysis or enrichment, we need to be able to read said content. That's what optical character recognition (OCR) is for. Given an image, a PDF or even a PDF with embedded OCR, how do we get to the content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Tesseract\n",
    "Tesseract is the state-of-the-art open source OCR software, and quite [easy to install](https://tesseract-ocr.github.io/tessdoc/Installation.html) except for the Windows version, which can be tricky.\n",
    "### Windows\n",
    "1. Download the Tesseract .exe file https://github.com/tesseract-ocr/tesseract/releases/download/5.5.0/tesseract-ocr-w64-setup-5.5.0.20241111.exe \n",
    "2. Click on the file in your Downloads folder and follow the installation wizard's instructions. The only thing you might have to change is to add more languages when prompted for which language packages you might need. **IMPORTANT** Write down where the Tesseract is being installed! It's in the step \"Zielverzeichnis wählen\" and for me it looks like: \n",
    "```shell\n",
    "C:\\Users\\USERNAME\\AppData\\Local\\Programs\\Tesseract-OCR\n",
    "```\n",
    "Add this to your system path.\n",
    "\n",
    "3. Let's say during installation you did not add all the language packs you need. A list of languages Tesseract offers can be found <i>[here](https://github.com/tesseract-ocr/tessdata)</i>. The German package is <i>[here](https://github.com/tesseract-ocr/tessdata/blob/main/deu.traineddata)</i> where you can download it.\n",
    "\n",
    "4. Now all you need to do is move the file \"deu.traineddata\" into  \n",
    "```shell\n",
    "C:\\Users\\USERNAME\\AppData\\Local\\Programs\\Tesseract-OCR\\tessdata\n",
    "```\n",
    "where eng.traineddata already is!\n",
    "\n",
    "**NOTE** Because of the way that Tesseract is installed, Python might not be able to find it. Thus, you can either add it to your SystemPath (as I described above), or whenever you use it, you can add the line \n",
    "```\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\USERNAME\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "```\n",
    "After you import pytesseract. This helps Python know where to look for your files.\n",
    "\n",
    "### Multi-Language support\n",
    "But OCR is a visual problem, it simply reads in the pixels and tries to re-construct the word that way, so why are there several languages for Tesseract? Modern OCR tools use context and dictionaries as well, in order to improve their performance. This leads to catching words such as \"tne\" which is supposed to be \"the\" for instance. If the language is English, \"fur\" is likely supposed to be \"for\" whereas in German the correction might be \"für\". On the other hand, \"fur\" is a valid English word, thus the context comes in. All of this together led to extraordinary performance improvements over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract #https://pypi.org/project/pytesseract/\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\USERNAME\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "from jiwer import cer #https://pypi.org/project/jiwer/\n",
    "import os\n",
    "from PIL import Image\n",
    "from nltk.metrics.distance import _edit_dist_step, _edit_dist_init, _last_left_t_init\n",
    "import re\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF **with embedded text**\n",
    "This might seem misplaced in the OCR notebook, but it's important to not only be able to *create* OCR for files but also be able to *extract* it from files which already have it!\n",
    "\n",
    "We show this on the example of PDFs from the [E-Periodica](https://www.e-periodica.ch/) archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath_list = ['data/grs-001_1921_13__298_d.pdf', 'data/grs-001_1921_13__393_d.pdf',\n",
    "                 'data/grs-001_1922_14__563_d.pdf', 'data/grs-001_1923_15__447_d.pdf']\n",
    "for filePath in filePath_list:\n",
    "\n",
    "    pdf_doc = fitz.open(filePath)\n",
    "    page = pdf_doc[1:]  # page 1 is just the metadata for the document\n",
    "    pdf_text = \"\\n\".join([x.get_text() for x in page])  # I deliberately add newlines so we can nicely put words back together that were split across the pages\n",
    "    pdf_text = re.sub(\"¬\\n\", \"\", pdf_text)  # \"bindestriche\" will be removed, if they are followed by one or several whitespaces, those will be removed as well.\n",
    "    pdf_text = pdf_text.strip()\n",
    "    pdf_text = re.sub(\"\\n\", \" \", pdf_text)  # replace newlines with spaces\n",
    "    pdf_text = re.sub(r'\\s+', \" \", pdf_text)  # replace all repeating whitespaces with only one whitespace\n",
    "    pdf_text = re.sub(r'\\\\', \"\", pdf_text)  # replace all double backslashes\n",
    "\n",
    "    #save the pure text in a new file, we'll re-use this in the embedding_data notebook\n",
    "    with open(filePath.replace(\".pdf\",\".txt\").replace(\"data/\", \"data/embedding_data/\"), \"w\") as f:\n",
    "        f.write(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytesseract\n",
    "If you have a file without embedded text, you need to run OCR on it first. State-of-the-art (in open-source but it can even hold its own against proprietary solutions!) at the moment is Tesseract so that's what we're using here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF\n",
    "Note that this PDF has embedded text, but we throw it away and run pytesseract on it for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'data/grs-001_1921_13__298_d.pdf'\n",
    "doc = fitz.open(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we print the data page by page as opposed to joining them so we can examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_number in range(doc.page_count):\n",
    "    page = doc.load_page(page_number)\n",
    "    pix = page.get_pixmap()\n",
    "    pix.save(f\"aux-{page_number}.jpeg\", \"jpeg\") # this is to avoid having to use pdf2image which is a nightmare for Windows\n",
    "    txt = pytesseract.image_to_string(f\"aux-{page_number}.jpeg\", lang=\"deu\")\n",
    "    print(\"Page # {} - {}\".format(str(page_number),txt))\n",
    "    os.remove(f\"aux-{page_number}.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image\n",
    "Images (usually) don't have embedded OCR, so here we don't have to throw anything away and simply run pytesseract on a jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_image_example_filepaths = [\"data/ocr_data/grs-001_1921_013_0051.jpg\", \"data/ocr_data/grs-001_1921_013_0052.jpg\"]\n",
    "ocr_image_example_text = \"\"\n",
    "for path in ocr_image_example_filepaths:\n",
    "    text = pytesseract.image_to_string(Image.open(path), lang='deu')\n",
    "    text = re.sub(\"¬\\s+\", \"\", text)  # \"bindestriche\" will be removed, if they are followed by one or several whitespaces, those will be removed as well.\n",
    "    text = text.strip() \n",
    "    text = re.sub(\"\\n\", \" \", text)  # replace newlines with spaces\n",
    "    text = re.sub(r'\\s+', \" \", text)  # replace all repeating whitespaces with only one whitespace\n",
    "    text = re.sub(r'\\\\', \"\", text)  # replace all double backslashes\n",
    "    ocr_image_example_text += text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_image_example_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! But how do we know if it actually is well done OCR? One evaluation metric is the so-called \"character error rate\". We don't have \"ground-truth\" (GT) to compare it with, so we'll use the E-Periodica OCR as GT and compare the Tesseract result to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily we already extracted just the text from the PDF files on E-Periodica, so we just open them back up here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/embedding_data/grs-001_1921_13__298_d.txt\", \"r\") as f:\n",
    "    pdf_doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cer(pdf_doc, ocr_image_example_text)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A character error rate of 2% is already extremely low, but as you might have already noticed by examining our examples, we can lower it even further. The Tesseract OCR splits words with a regular dash \"-\" instead of the correct one for words which were split because they go over the line \"¬\" so this is not caught by our pre-processing. Let's change that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_image_example_text_fixed_bindestrich = \"\"\n",
    "for path in ocr_image_example_filepaths:\n",
    "    text = pytesseract.image_to_string(Image.open(path), lang='deu')\n",
    "    text = re.sub(r\"(?<=\\w)-\\n\", \"\", text)  # this is the line we changed\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(r'\\s+', \" \", text)\n",
    "    text = re.sub(r'\\\\', \"\", text)\n",
    "    ocr_image_example_text_fixed_bindestrich += text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we did not simply replace \"¬\" by \"-\", since they are not used in the same way, and there might still be valid other occurrences of \"-\" within the text. What we did instead is check if before \"-\" there is a word and after there is a space, to not catch words such as \"E-Mail\" for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cer(pdf_doc, ocr_image_example_text_fixed_bindestrich)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/embedding_data/grs-001_1921_13__298_d_tesseract.txt\",\"w\") as f:\n",
    "    f.write(ocr_image_example_text_fixed_bindestrich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/embedding_data/grs-001_1921_13__298_d_tesseract.txt\",\"r\") as f:\n",
    "    ocr_image_example_text_fixed_bindestrich = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go! A CER of 0.8%, as we would have expected for a combination of Tesseract, printed text and a very simple layout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-correction with edit distance\n",
    "Can we do better? Looking at the Tesseract OCR, it's already very high quality, but there are several seemingly \"obvious\" mistakes, such as \"Ohancen\" instead of \"Chancen\" or \"eiustimmig\" instead of \"einstimmig\". A naive way to address this is via \"lexicon method\", where you check if the word you found through visual methods even exists in the lexicon of that language.\n",
    "\n",
    "Of course, there are several caveats to this which are also the reason why Tesseract did not correct these words. (1) You cannot be sure that you have a complete vocabulary with all declensions, conjugations etc. (2) Names are usually not part of a vocabulary and even if they are, see point (1). (3) Sometimes, especially in our Swiss dataset, words from other languages are used in a regular German sentence, so you would -correctly- flag \"trottoir\" as not a valid German word and then look for the most similar (in terms of edit-distance) German word in your vocabulary. This is called \"verschlimmbessern\" in German.\n",
    "\n",
    "Still, especially for names, this type of post-correction can be very rewarding. We address some of these concerns by setting the allowed edit distance very low and even making it depend on the word length. Let's try it on our current example and see if it makes our CER better or worse.\n",
    "\n",
    "As a lexicon we downloaded all of German Wikipedia and because our dataset is Swiss we added all the Swiss person names from the Bundesamt für Statistik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit_distance\n",
    "import json\n",
    "with open('data/word_count_dewiki_chnames.json', 'r', encoding='utf8') as file:\n",
    "    german_word_set = json.load(file)\n",
    "german_word_set = set(k for k, v in german_word_set.items() if v > 3 and len(k)>1)  # only consider words which appear at least three times, to avoid typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_checking(text, lexicon):\n",
    "    word_count = 0\n",
    "    word_in_dict_count = 0\n",
    "    words_not_in_dict = []\n",
    "    patt = r'[a-zA-ZäöüÄÖÜß]+'\n",
    "    for word in re.finditer(patt, text):\n",
    "        word = word.group()\n",
    "        word_count +=1\n",
    "        if word in lexicon or word.lower() in lexicon:\n",
    "            word_in_dict_count += 1\n",
    "        else:\n",
    "            words_not_in_dict.append(word)\n",
    "    return word_in_dict_count/word_count*100, words_not_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_results_pdf = lexicon_checking(pdf_doc, german_word_set)\n",
    "lex_results_ocr = lexicon_checking(ocr_image_example_text_fixed_bindestrich, german_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The percentage of words in dictionary for: \\n pdf: {lex_results_pdf[0]:.2f} \\n tesseract: {lex_results_ocr[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The words not found in the lexicon for: \\n pdf: {lex_results_pdf[1]} \\n tesseract {lex_results_ocr[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_word_set_list = list(german_word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one small note about the edit distance: To compute the full edit distance (including being able to track the edits and not just the distance itself), there is no way around computing the entire memoization table, which is very slow (O(N*M) where N is the length of the first string and M is the length of the second string). But we have an additional constraint! We don't want the edit distance to be larger than k (in our case, k=2). This enables us to do two things:\n",
    "\n",
    "(1) Before we compute anything we check if the difference in length between the two strings is larger than k, if yes, we break. The edit distance would have been too large regardless.\n",
    "\n",
    "(2) If each value of an entire row is larger than our max edit distance, you break and return that it is too large of a distance.\n",
    "\n",
    "This doesn't change the asymptotic complexity (for that you would need to do some more index tricks), but it reduces our actual compute time significantly. The function below is a method from nltk.metrics.distance I adapted as explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(s1, s2, substitution_cost=1, transpositions=False, max_changes=2):\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein edit-distance between two strings.\n",
    "    The edit distance is the number of characters that need to be\n",
    "    substituted, inserted, or deleted, to transform s1 into s2.  For\n",
    "    example, transforming \"rain\" to \"shine\" requires three steps,\n",
    "    consisting of two substitutions and one insertion:\n",
    "    \"rain\" -> \"sain\" -> \"shin\" -> \"shine\".  These operations could have\n",
    "    been done in other orders, but at least three steps are needed.\n",
    "\n",
    "    Allows specifying the cost of substitution edits (e.g., \"a\" -> \"b\"),\n",
    "    because sometimes it makes sense to assign greater penalties to\n",
    "    substitutions.\n",
    "\n",
    "    This also optionally allows transposition edits (e.g., \"ab\" -> \"ba\"),\n",
    "    though this is disabled by default.\n",
    "\n",
    "    :param s1, s2: The strings to be analysed\n",
    "    :param transpositions: Whether to allow transposition edits\n",
    "    :type s1: str\n",
    "    :type s2: str\n",
    "    :type substitution_cost: int\n",
    "    :type transpositions: bool\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    # set up a 2-D array\n",
    "    len1 = len(s1)\n",
    "    len2 = len(s2)\n",
    "    if abs(len1-len2) > max_changes:\n",
    "        return max_changes+1\n",
    "    lev = _edit_dist_init(len1 + 1, len2 + 1)\n",
    "\n",
    "    # retrieve alphabet\n",
    "    sigma = set()\n",
    "    sigma.update(s1)\n",
    "    sigma.update(s2)\n",
    "\n",
    "    # set up table to remember positions of last seen occurrence in s1\n",
    "    last_left_t = _last_left_t_init(sigma)\n",
    "\n",
    "    # iterate over the array\n",
    "    # i and j start from 1 and not 0 to stay close to the Wikipedia pseudo-code\n",
    "    # see https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n",
    "    for i in range(1, len1 + 1):\n",
    "        last_right_buf = 0\n",
    "        for j in range(1, len2 + 1):\n",
    "            last_left = last_left_t[s2[j - 1]]\n",
    "            last_right = last_right_buf\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                last_right_buf = j\n",
    "            _edit_dist_step(\n",
    "                lev,\n",
    "                i,\n",
    "                j,\n",
    "                s1,\n",
    "                s2,\n",
    "                last_left,\n",
    "                last_right,\n",
    "                substitution_cost=substitution_cost,\n",
    "                transpositions=transpositions,\n",
    "            )\n",
    "        last_left_t[s1[i - 1]] = i\n",
    "        if min(lev[i]) > max_changes:  # max distance I allow\n",
    "            return max_changes+1  # just a way of saying it's larger than allowed\n",
    "    return lev[len1][len2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even with these changes, the code below is extremely slow. We still have to compare each word in our example text to each word in our vocabulary, even though the actual computation of the edit distance is a bit faster now. \n",
    "\n",
    "If this is done many times, it would be better to construct a data-structure exactly made for this type of checking, where you already save the vocabulary in such a way that the substrings can easily be found (this is vague and even so extremely simplified. [This blogpost](http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata) on the topic is very illuminating if you would like to learn more and don't know where to start.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_image_example_text_fixed_bindestrich_fixedvocab = ocr_image_example_text_fixed_bindestrich\n",
    "patt = r'[a-zA-ZäöüÄÖÜß]+'\n",
    "german_word_set_list = list(german_word_set)\n",
    "num_characters_changed = 0\n",
    "max_changes = 2\n",
    "for word in tqdm(re.finditer(patt, ocr_image_example_text_fixed_bindestrich)): # around 2k words takes 16 minutes\n",
    "    if word.group() not in german_word_set and word.group().lower() not in german_word_set:\n",
    "        \n",
    "        # don't correct short words\n",
    "        if len(word.group()) <= 3:\n",
    "              continue\n",
    "        \n",
    "        # don't correct words that appear like that in the gt pdf as well\n",
    "        if word.group().lower() in pdf_doc.lower():\n",
    "            continue\n",
    "        \n",
    "        # find the closest one\n",
    "        closest_word = \"\"\n",
    "        min_dist = max_changes+1\n",
    "        for ger_word in german_word_set_list:\n",
    "            d = edit_distance(word.group(), ger_word)\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "                closest_word = ger_word\n",
    "                if min_dist == 1: #cannot get better than this\n",
    "                    break\n",
    "\n",
    "        if min_dist > max_changes:\n",
    "            continue\n",
    "\n",
    "        print(word)\n",
    "        print(closest_word)\n",
    "\n",
    "        ocr_image_example_text_fixed_bindestrich_fixedvocab =\\\n",
    "            ocr_image_example_text_fixed_bindestrich_fixedvocab[:word.start()+num_characters_changed]\\\n",
    "            + closest_word\\\n",
    "                + ocr_image_example_text_fixed_bindestrich_fixedvocab[word.end()+num_characters_changed:]\n",
    "        num_characters_changed += len(closest_word)-len(word.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cer(pdf_doc, ocr_image_example_text_fixed_bindestrich_fixedvocab)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, that helped but barely. Considering how long it takes to compute, this is likely not a viable next step for most use-cases, but it's important to keep in mind for situations where small typos are unacceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/embedding_data/grs-001_1921_13__298_d_tesseract_vocabulary_fixes.txt\",\"w\") as f:\n",
    "    f.write(ocr_image_example_text_fixed_bindestrich_fixedvocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten text recognition (HTR)\n",
    "This is much trickier, and depends entirely on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we begin with some botanical images, where only certain parts of the image contain nicely written labels.\n",
    "\n",
    "For handwritten text recognition, the best out-of-the-box tool at the moment is probably [Transkribus](https://app.transkribus.org/). But we don't have access to those models and cannot fine-tune them, unless we pay for a premium account and do it through their own website. An alternative for handwritten text recognition is the [Kraken project](https://kraken.re/main/index.html), which gives us access to dozens of pre-trained models which we can download and use ourselves. You can install Kraken easily via `pip install kraken`.\n",
    "\n",
    "NOTE: Unfortunately a Kraken version for Python 3.13 has still not been released (by December 2025) so to use it and run the following code cells you need to change to Python 3.12, then restart the kernel. For Windows you can get Python 3.12 via:\n",
    "\n",
    "`winget install python.python.3.12` \n",
    "\n",
    "then deactivate the current environment and simply create a new environment with this Python:\n",
    "```\n",
    "deactivate\n",
    "py -3.12 -m venv \"env_datastories_py312\"\n",
    ".\\env_datastories_py312\\Scripts\\activate.bat\n",
    "pip install wheel\n",
    "pip install ipykernel\n",
    "pip install kraken\n",
    "```\n",
    "\n",
    "Don't forget to change it at the top right for the notebook as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the [fondue model](https://github.com/FoNDUE-HTR/), which was trained for handwritten text recognition. We use the German one (\"_de\"), the Latin one (\"_la\") and the general one. That is because the labels themselves are mostly in German, but since they're plant species, many of their names are in Latin. Let's compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download some Kraken models off of [Zenodo](https://zenodo.org/records/14399779):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o ./data/kraken_models/FoNDUE-GD_v2.mlmodel https://zenodo.org/records/14399779/files/FoNDUE-GD_v2.mlmodel?download=1\n",
    "!curl -o ./data/kraken_models/FoNDUE-GD_v2_de.mlmodel https://zenodo.org/records/14399779/files/FoNDUE-GD_v2_de.mlmodel?download=1\n",
    "!curl -o ./data/kraken_models/FoNDUE-GD_v2_la.mlmodel https://zenodo.org/records/14399779/files/FoNDUE-GD_v2_la.mlmodel?download=1\n",
    "!curl -o ./data/kraken_models/McCATMuS_nfd_nofix_V1.mlmodel https://zenodo.org/records/13788177/files/McCATMuS_nfd_nofix_V1.mlmodel?download=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the text recognition on the given pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kraken -i data/ocr_data/Z-000033489.jpg data/ocr_data/output/Z-000099226_fondue_gd_v2_de.txt segment -bl ocr -m ./data/kraken_models/FoNDUE-GD_v2_de.mlmodel\n",
    "!kraken -i data/ocr_data/Z-000033489.jpg data/ocr_data/output/Z-000099226_fondue_gd_v2_la.txt segment -bl ocr -m ./data/kraken_models/FoNDUE-GD_v2_la.mlmodel\n",
    "!kraken -i data/ocr_data/Z-000033489.jpg data/ocr_data/output/Z-000099226_fondue_gd_v2.txt segment -bl ocr -m ./data/kraken_models/FoNDUE-GD_v2.mlmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally save (and print!) the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ocr_data/output/Z-000099226_fondue_gd_v2_de.txt\") as f:\n",
    "    de_result = f.read()\n",
    "    print(de_result)\n",
    "\n",
    "with open(\"data/ocr_data/output/Z-000099226_fondue_gd_v2_la.txt\") as f:\n",
    "    la_result = f.read()\n",
    "    print(la_result)\n",
    "\n",
    "with open(\"data/ocr_data/output/Z-000099226_fondue_gd_v2.txt\") as f:\n",
    "    general_result = f.read()\n",
    "    print(general_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't work as well as the printed OCR, but fairly readable.\n",
    "\n",
    "On the other hand, here we have some notary pages from the Archief Amsterdam, in English. Although it may seem that this is hastily written, given the other documents in their archive this is actually fairly nice handwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kraken -i \"data/ocr_data/d837ae03-b2c5-6b6d-e053-b784100acdee_en.jpg\" \"data/ocr_data/output/d837ae03-b2c5-6b6d-e053-b784100acdee_en_McCATMuS_nfd_nofix_V1.txt\" segment -bl ocr -m ./data/kraken_models/McCATMuS_nfd_nofix_V1.mlmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ocr_data/output/d837ae03-b2c5-6b6d-e053-b784100acdee_en_McCATMuS_nfd_nofix_V1.txt\", encoding=\"utf8\") as f:\n",
    "    notary_res = f.read()\n",
    "    print(notary_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This didn't work very well, in large part due to the fact that the model was not trained on this handwriting.\n",
    "\n",
    "As you can see, handwritten text recognition is a much more difficult task. For most use-cases, Transkribus will do just fine. But if you have a lot of data and would like to feed it back into your custom pipeline, it becomes necessary to utilize Kraken models (or something similar) and fine-tune them on your own. That is because Transkribus does not make it easy to programmatically (a) Upload your own transcribed data and (b) Download their transcriptions in a useful format, within your own pipeline again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_datastories",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
