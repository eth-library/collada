{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract #https://pypi.org/project/pytesseract/\n",
    "from jiwer import cer #https://pypi.org/project/jiwer/\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "from PIL import Image\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from tika import parser\n",
    "import re\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytesseract\n",
    "If you have a file without embedded text, you need to run OCR on it first. State of the art at the moment is tesseract so that's what we're using here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF\n",
    "Note that this PDF has embedded text, but we throw it away and run pytesseract on it for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'data/ocr_data/szg-005_1925_5__698_d.pdf'\n",
    "doc = convert_from_path(filePath)\n",
    "path, fileName = os.path.split(filePath)\n",
    "fileBaseName, fileExtension = os.path.splitext(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_number, page_data in enumerate(doc):\n",
    "    txt = pytesseract.image_to_string(page_data, lang=\"deu\")\n",
    "    print(\"Page # {} - {}\".format(str(page_number),txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image\n",
    "Images (usually) don't have embedded OCR, so here we don't have to throw anything away and simply run pytesseract on a jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(Image.open('data/ocr_data/grs-002_1984_076_0017.jpg'), lang='deu')\n",
    "text = text.replace(\"\\n\",\" \").replace(\"  \",\" \")#to better compare with our GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bei Sulzer in Winterthur kommt die Ausweispflicht Was wird kontrolliert? Als man vernahm, dass im Laufe dieses Jahres beim Sulzer-Konzern in Winterthur die Ausweispflicht mittels einer maschinenlesbaren Karte eingeführt werden soll, da dachte man als Gewerkschafter unwillkürlich an die vielen Möglichkeiten der Kontrolle der Arbeitnehmer, welche via elektronische Datenverarbeitung gegeben sind. «Neue Kontrollen mit neuen Technologien» heisst ja auch eine Broschüre, die der Österreichi- sche, der Luxemburgische und der Schweizerische Gewerkschaftsbund miteinander herausgebracht haben!. Darin wird gezeigt, was mit einem maschinenlesbaren Personalausweis im Betrieb alles gemacht werden kann. Die Redaktion der «Gewerkschaftlichen Rundschau» fand es des- halb für angebracht, sich in Winterthur beim Schweizerischen Metall- und Uhrenarbeitnehmer-Verband (SMUV) und bei der Sulzer-Betriebs- kommission, die der Einführung des Ausweises zugestimmt hat, zu er- kundigen, was mit dem kommenden Ausweis erfasst werden soll und wie die Arbeitnehmer und ihre Vertreter sich vor Missbrauch zu schützen gedenken. Arnold Isler sprach mit dem SMUV-Vizepräsidenten Agostino Tarabusi, dem Winterthurer SMUV-Lokalsekretär Kurt Schaufelberger, dem Präsidenten der Sulzer-Betriebskommission Walter Wickihalder, und dem Betriebskommissionsmitglied Ro/f Wirth, der sich speziell mit diesen Problemen beschäftigt. Nur Zutrittskontrolle Isler: Rund 11 000 Sulzer-Mitarbeiter werden in einigen Monaten einen maschinenlesbaren Ausweis tragen müssen, wenn sie sich auf dem Gelände eines der Sulzer- Betriebe in Winterthur aufhalten. Wie soll das genau funktionieren? Wickihalder: Ganz genau weiss man das noch nicht. Da ist noch einiges in Prüfung. Es geht darum, dass jeder Mitarbeiter und jede Mitarbeiterin von Sulzer einen Ausweis trägt, der ihm oder ihr den Zutritt ins Sulzerge- lände ermöglicht. Auf diesem Ausweis steht vorn der Name, die Ab- teilung des Inhabers und noch ein Vermerk, ob er zum Beispiel zu den Sperrzonen Zutritt hat. Hinten ist ein Magnetband, welches das elek- tronische Lesen ermöglicht. Isler: Welches sind die Sperrzonen? Wickihalder: Die Forschungsabteilung, das Computerzentrum, das Ver- waltungsgebäude. Isler: Sulzer spricht davon, man habe diesen Ausweis aus Sicherheits- gunden schaffen müssen, um die Risiken zu verkleinern. Was sind das für Risiken. Wirth: Da sind wir mit der Firma einverstanden. Es geht nicht nur um 10 \\x0c'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! But how do we know if it actually is well done OCR? Once evaluation metric is the so-called \"character error rate\". We don't have \"ground-truth\" to compare it with, so we'll use the E-Periodica OCR as GT and compare the tesseract result to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parser.from_file('data/ocr_data/grs-002_1984_076_0017.pdf')\n",
    "#pdf\n",
    "contents = [x.strip() for x in parsed[\"content\"].split(\"\\n\") if x != \"\"]\n",
    "#remove the first page\n",
    "article = \" \".join(contents)\n",
    "\n",
    "article = re.sub(\"¬\\s+\", \"\", article)  # \"bindestriche\" will be removed, if they are followed by one or several whitespaces, those will be removed as well.\n",
    "article = article.strip()  # remove all starting and trailing whitespaces\n",
    "article = re.sub(\"\\n\", \" \", article)  # replace newlines with spaces\n",
    "article = re.sub(\"\\. \", \"\\.\\n\", article)  # replace periods with newlines (for nicer printing)\n",
    "article = re.sub(r'\\s+', \" \", article)  # replace all repeating whitespaces with only one whitespace\n",
    "article = re.sub(r'\\\\', \"\", article)  # replace all double backslashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate if you have ground truth (perfect transcription)\n",
    "#here we take the eperiodica text as perfect transcription\n",
    "gt = article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bei Sulzer in Winterthur kommt die Ausweispflicht Was wird kontrolliert? Als man vernahm, dass im Laufe dieses Jahres beim Sulzer-Konzern in Winterthur die Ausweispflicht mittels einer maschinenlesbaren Karte eingeführt werden soll, da dachte man als Gewerkschafter unwillkürlich an die vielen Möglichkeiten der Kontrolle der Arbeitnehmer, welche via elektronische Datenverarbeitung gegeben sind. «Neue Kontrollen mit neuen Technologien» heisst ja auch eine Broschüre, die der Österreichi- sche, der Luxemburgische und der Schweizerische Gewerkschaftsbund miteinander herausgebracht haben!. Darin wird gezeigt, was mit einem maschinenlesbaren Personalausweis im Betrieb alles gemacht werden kann. Die Redaktion der «Gewerkschaftlichen Rundschau» fand es des- halb für angebracht, sich in Winterthur beim Schweizerischen Metall- und Uhrenarbeitnehmer-Verband (SMUV) und bei der Sulzer-Betriebs- kommission, die der Einführung des Ausweises zugestimmt hat, zu er- kundigen, was mit dem kommenden Ausweis erfasst werden soll und wie die Arbeitnehmer und ihre Vertreter sich vor Missbrauch zu schützen gedenken. Arnold Isler sprach mit dem SMUV-Vizepräsidenten Agostino Tarabusi, dem Winterthurer SMUV-Lokalsekretär Kurt Schaufelberger, dem Präsidenten der Sulzer-Betriebskommission Walter Wickihalder, und dem Betriebskommissionsmitglied Ro/f Wirth, der sich speziell mit diesen Problemen beschäftigt. Nur Zutrittskontrolle Isler: Rund 11 000 Sulzer-Mitarbeiter werden in einigen Monaten einen maschinenlesbaren Ausweis tragen müssen, wenn sie sich auf dem Gelände eines der Sulzer- Betriebe in Winterthur aufhalten. Wie soll das genau funktionieren? Wickihalder: Ganz genau weiss man das noch nicht. Da ist noch einiges in Prüfung. Es geht darum, dass jeder Mitarbeiter und jede Mitarbeiterin von Sulzer einen Ausweis trägt, der ihm oder ihr den Zutritt ins Sulzerge- lände ermöglicht. Auf diesem Ausweis steht vorn der Name, die Ab- teilung des Inhabers und noch ein Vermerk, ob er zum Beispiel zu den Sperrzonen Zutritt hat. Hinten ist ein Magnetband, welches das elek- tronische Lesen ermöglicht. Isler: Welches sind die Sperrzonen? Wickihalder: Die Forschungsabteilung, das Computerzentrum, das Ver- waltungsgebäude. Isler: Sulzer spricht davon, man habe diesen Ausweis aus Sicherheits- gunden schaffen müssen, um die Risiken zu verkleinern. Was sind das für Risiken. Wirth: Da sind wir mit der Firma einverstanden. Es geht nicht nur um 10'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = cer(gt, text)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a great example because tesseract and ABBYY reader agreed perfectly... hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-correction with edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten\n",
    "This is much trickier, and depends entirely on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we begin with some botanical images, where just certain parts of the image contain nicely written labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ANN /home/genta/Documents/notebooks_cs/.venv/lib/python3.8/site-packages/kraken/blla.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN FoNDUE-GD_v2_de.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Segmenting\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m15/15\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:02\u001b[0mm \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hWriting recognition results for data/ocr_data/Z-000033489.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN /home/genta/Documents/notebooks_cs/.venv/lib/python3.8/site-packages/kraken/blla.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN FoNDUE-GD_v2_la.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Segmenting\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m15/15\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:02\u001b[0mm \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hWriting recognition results for data/ocr_data/Z-000033489.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN /home/genta/Documents/notebooks_cs/.venv/lib/python3.8/site-packages/kraken/blla.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN FoNDUE-GD_v2.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Segmenting\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m15/15\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:02\u001b[0mm \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hWriting recognition results for data/ocr_data/Z-000033489.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kraken -i data/ocr_data/Z-000033489.jpg data/ocr_data/output/Z-000099226_fondue_gd_v2_de.txt segment -bl ocr -m FoNDUE-GD_v2_de.mlmodel\n",
    "!kraken -i data/ocr_data/Z-000033489.jpg data/ocr_data/output/Z-000099226_fondue_gd_v2_la.txt segment -bl ocr -m FoNDUE-GD_v2_la.mlmodel\n",
    "!kraken -i data/ocr_data/Z-000033489.jpg data/ocr_data/output/Z-000099226_fondue_gd_v2.txt segment -bl ocr -m FoNDUE-GD_v2.mlmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't work as well as the printed OCR, but fairly readable.\n",
    "\n",
    "On the other hand, here we have some notary pages from the Archief Amsterdam, in English. Although it may seem that this is hastily written, given the other documents in their archive this is actually quite nice handwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kraken -i \"data/d837ae03-b2c5-6b6d-e053-b784100acdee_en.jpg\" \"data/ocr_data/output/d837ae03-b2c5-6b6d-e053-b784100acdee_en_McCATMuS_nfd_nofix_V1.txt\" segment -bl ocr -m McCATMuS_nfd_nofix_V1.mlmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This didn't work very well, in large part due to the fact that the model was not trained on this handwriting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text to TEI xml with spacy NER\n",
    "Humanities use XML files a lot, and NER works quite nicely with a typical OCR file structure. Here we take a text file, run NER on it and save it as a TEI XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -o output.xml -F upload=@grs-002_1984_76__277_d.txt https://teigarage.tei-c.org/ege-webservice/Conversions/txt%3Atext%3Aplain/odt%3Aapplication%3Avnd.oasis.opendocument.text/TEI%3Atext%3Axml/conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = \"data/ocr_data/grs-002_1984_76__277_d.txt\"\n",
    "output_file = \"data/ocr_data/output/grs-002_1984_76__277_d_tei.xml\"\n",
    "output_file_ner = \"data/ocr_data/output/grs-002_1984_76__277_d_tei_ner.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genta/Documents/notebooks_cs/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tei_from_txt(txt_file, output_file, paragraph_delimiter=\"\\n\", page_delimiter=\"\\n\\n\",):\n",
    "    #TODO add line breaks?\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    pages = text.split(page_delimiter)\n",
    "    paragraphs = [x.split(paragraph_delimiter) for x in pages]\n",
    "\n",
    "    tei = Element('teiHeader') #root\n",
    "    text_section = SubElement(tei, 'text')\n",
    "    body = SubElement(text_section, 'body')\n",
    "    \n",
    "    for page in paragraphs:\n",
    "        p_page = SubElement(body,\"pb\")\n",
    "        for paragraph in page:\n",
    "            doc = nlp(paragraph)\n",
    "            p_para = SubElement(p_page, 'p')  # Paragraph element\n",
    "            p_para.text = paragraph\n",
    "            #paragraph_ = insert_entity_tags_as_xml(text, doc.ents,p_para)\n",
    "            #p_para.extend(paragraph_)\n",
    "    \n",
    "    # Generate the output XML file\n",
    "    tree = ElementTree(tei)\n",
    "    tree.write(output_file, encoding='utf-8', xml_declaration=True)\n",
    "    \n",
    "    print(f\"TEI file created: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI file created: data/ocr_data/output/grs-002_1984_76__277_d_tei.xml\n"
     ]
    }
   ],
   "source": [
    "create_tei_from_txt(txt_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_tei_from_tei(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        xml_doc = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(xml_doc, \"xml\")\n",
    "\n",
    "    paragraphs = soup.find_all(string=True)\n",
    "    for entry in paragraphs:\n",
    "\n",
    "        doc = nlp(entry.text)\n",
    "        newtext = entry\n",
    "        last_tag = \"\"\n",
    "        for i,ent in enumerate(doc.ents):\n",
    "            start = ent.start_char + i*(5+len(last_tag))\n",
    "            end = ent.end_char + i*(5+len(last_tag))\n",
    "            entity_text = ent.text\n",
    "            entity_label = ent.label_\n",
    "\n",
    "            if entity_label == \"PER\":\n",
    "                tag = \"perName\"\n",
    "            elif entity_label == \"ORG\":\n",
    "                tag = \"orgName\"\n",
    "            elif entity_label == \"GPE\" or entity_label == \"LOC\":\n",
    "                tag = \"placeName\"\n",
    "            elif entity_label == \"MONEY\":\n",
    "                tag = \"monetaryAmount\"\n",
    "            else:\n",
    "                tag = entity_label\n",
    "            \n",
    "            newtext = newtext[:start] + \"<\"+tag+\">\"+entity_text+\"</\"+tag+\">\" + newtext[end + 1:]\n",
    "            last_tag = tag\n",
    "        \n",
    "        entry.replace_with(BeautifulSoup(newtext, features=\"html.parser\"))\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ner_tei_from_tei(output_file, output_file_ner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
